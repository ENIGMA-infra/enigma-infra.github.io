{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to the ENIGMA infra documentation","text":"<p>This site provides an overview of the ENIGMA infrastructure project. Please refer to ENIGMA website for more information on the consortium. </p> <ul> <li> <p> Infra Team</p> <p> People behind enigma-infra</p> </li> <li> <p> Enigma sites</p> <p> Global study populations</p> </li> <li> <p> Institute Partners</p> <p> Letters of support</p> </li> <li> <p> Testimonials</p> <p> Reviews from our early adopters</p> </li> <li> <p> Resources</p> <p> Neuroinformatic tools</p> </li> <li> <p> Blogs</p> <p> Progress updates</p> </li> </ul>"},{"location":"#partnering-institutes","title":"Partnering institutes","text":""},{"location":"blog/","title":"ENIGMA-infra Blog","text":"<p>Follow the progress of the ENIGMA infrastructure project through our blog posts below.  </p>"},{"location":"blog/2025/08/29/post-title/","title":"Post title","text":""},{"location":"blog/2025/08/29/post-title/#coming-soon","title":"Coming soon...","text":""},{"location":"partners/Helmich/","title":"Rick Helmich, MD PhD, Associate Professor, Donders Institute, Radboud University, Nijmegen, Netherlands","text":"<p>My main motivation for supporting ENIGMA-PD and the use of Nipoppy and Neurobagel tools is that science benefits from large and diverse datasets, and these initiatives are instrumental in making existing datasets visible and accessible to the larger neuroscience community. What helps is the fact that raw data stay at each location, as well as short ties between involved researchers and centers, and a smaller, dedicated group of scientists who coordinate the project. Long-term funding is crucial to support a scientific \u201ccore team\u201d that coordinates efforts within the larger community, provides help and supervision, and makes sure that software (e.g. analysis scripts for ENIGMA-PD, but also tools such as Nipoppy and Neurobagel) are \u201cplug-and-play\u201d. This may be challenging in the current funding landscape.</p>"},{"location":"partners/LoS/","title":"Institutional letters of support","text":"<ul> <li> <p>Dr. Paul Thompson, Director at ENIGMA Center for Worldwide Medicine, Imaging &amp; Genomics, Professor, University of Southern California:  \"... As PI for ENIGMA Consortium as a whole, I and my colleagues are immensely grateful for the work done to create an informatics infrastructure for ENIGMA-PD ... I am really impressed by the extremely well thought out efforts to create tools that allow scalable, reproducible analyses and there have been significant successes already ...\"</p> </li> <li> <p>Prof.dr. Wilma D.J. Van de Berg, President of Dutch Parkinson Scientists (DPS), Board member of the Parkinson Alliance, Professor, Amsterdam UMC:  \"... We are excited that ENIGMA-PD aims to further strengthen open science by adopting and reinforcing FAIR principles in world-wide data-sharing and support their grant application \u2018Working together openly in a private world: Preparing the international ENIGMA-PD consortium for the GDPR era by adopting FAIR principles\u2019 ...\"</p> </li> <li> <p>Neda Jahanshad, PhD, Associate Director, ENIGMA Consortium, Associate Professor, University of Southern California: \"...I am fortunate to have seen the Nipoppy and Neurobagel frameworks developed during the past years, and am excited for the potential of integrating these frameworks within the ENIGMA Consortium. The fast adoption of the tools by the ENIGMA Parkinson\u2019s disease working group is highly impressive ...\"</p> </li> <li> <p>Rick Helmich, MD PhD, Associate Professor, Radboud University, Nijmegen, Netherlands: \"... My main motivation for supporting ENIGMA-PD and the use of Nipoppy and Neurobagel tools is that science benefits from large and diverse datasets, and these initiatives are instrumental in making existing datasets visible and accessible to the larger neuroscience community ...\"</p> </li> </ul>"},{"location":"partners/Thompson/","title":"Dr. Paul Thompson, Director at ENIGMA Center for Worldwide Medicine, Imaging &amp; Genomics","text":"<p>Professor of Ophthalmology, Pediatrics, Neurology, Psychiatry and the Behavioral Sciences, Radiology, Biomedical Engineering, Electrical Engineering and Quantitative and Computational Biology, University of Southern California</p> <p>This is in response to a request for a brief comment on the implementation of Nipoppy and Neurobagel tools for the ENIGMA-PD datasets. As PI for ENIGMA Consortium as a whole, I and my colleagues are immensely grateful for the work done to create an informatics infrastructure for ENIGMA-PD. As detailed in the paper, the data organization, streamlining, and standardization of workflows has many benefits, including the ability to understand what meta-data are available, run reproducible analyses, and manage data and workflows as the project scales. As multisite analyses grow in scale (more sites, more data modalities) and as multiple projects are running concurrently, there are immense requirements for informatics systems that can handle the complexity of the data and how it is managed. I am really impressed by the extremely well thought out efforts to create tools that allow scalable, reproducible analyses and there have been significant successes already.  </p> <p>Looking beyond this project, there are some challenges  for other working groups/institutes/consortia trying to adopt similar standards and data practices. The Nipoppy team has handled these well. We all know that data management and informatics systems require resources (funding), skill, and dedicated interaction between technical teams and less technically skilled team members to help adopt these systems. In the long run, time is saved, and with better management, benefits accrue. In this case there were carefully structured in person meetings with the Nipoppy team traveling internationally to help address user questions. Having had their team visit us in person also, their commitment and skill is exceptional. There is a need for funding and dedicated personnel for these efforts to succeed, it cannot just be assumed that people will adopt them. Although in principle, in person hands-on interaction could be done remotely, in my experience this is challenging for all but the simplest tools, unless there is a large immediate pay-off. I have seen many good ideas that people do not adopt, due to limited attention span, overwhelm with other tasks, lack of time, and difficulty coordinating interactions on site. The in person aspect seems to have helped a lot here, as various simplifications (Zoom, conference workshops) do not always gain as much traction as an in person visit.</p>"},{"location":"resources/overview/","title":"ENIGMA-infra resources","text":"<p>Check out these resources for simplifying data curation, processing using Nipoppy, and how to perform visual quality control!</p> <ul> <li> <p> How to set up Nipoppy?</p> </li> <li> <p> Processing: FreeSurfer 7</p> </li> <li> <p> Processing: Subsegmentations</p> </li> <li> <p> Processing: fsqc</p> </li> <li> <p> Quality control: visual inspection</p> </li> </ul>"},{"location":"resources/overview/#learn-more-about-the-open-science-tools-that-can-facilitate-fairification-of-your-data-workflows","title":"Learn more about the open-science-tools that can facilitate FAIRification of your data workflows!","text":""},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/","title":"ENIGMA-PD Visual Quality Control Instructions","text":"<p>Welcome to the ENIGMA FreeSurfer Visual Quality Control Manual Last updated: August 2025</p> <p>This page outlines the recommended approach to visually inspect and rate FreeSurfer segmentations. The current instructions focus on cortical and subcortical structures only. Subsegmentation quality control will be added once guidelines are available.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#step-by-step-instructions-for-visual-inspection","title":"Step-by-step instructions for visual inspection","text":""},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#1-download-the-template-spreadsheets","title":"1. Download the template spreadsheets","text":"<ul> <li>Download the Cortical QC template</li> <li>Download the Subcortical QC template</li> </ul> <p>These templates should be filled in manually. The only changes to be made to these templates are 1) adding all subjects from your dataset in the first column (you can copy over file names from your nipoppy manifest file), and 2) changing quality control scores from <code>\"pass\"</code> to <code>\"fail\"</code> if needed. The cortical template contains two tabs: the first tab is used to record the visual inspection scores, while the second tab provides additional context on common quality control issues observed in ENIGMA projects.  You do not need to review or complete the second tab \u2014 it is included to stay consistent with the standard ENIGMA consortium template. The subcortical template consists of one tab, with the selected subcortical areas for visual inspection.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#2-learn-about-the-scoring","title":"2. Learn about the scoring","text":"<p>In the template spreadsheet, all regions are by default marked as a <code>\"pass\"</code>. Raters are asked to provide a score for each region: either <code>\"pass\"</code> or <code>\"fail\"</code>, no other values should be used.</p> <p>Be conservative when failing: Use the <code>\"fail\"</code> label only when there are obvious, serious issues that would make the regional estimates unreliable or unusable.  Small flaws or mild asymmetries are typically not enough to justify a fail. </p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#types-of-scores","title":"Types of scores","text":"<p>For the cortical quality control, you will complete several types of scores: an overall score for internal and external QC, and specific scores for each region, assessed separately for the left and right hemispheres. You may optionally add comments or a QC_code (as defined in the second tab of the spreadsheet), but these are not required for the ENIGMA-PD quality assessment.</p> <p>For the subcortical quality control, you will provide specific scores for each region, again assessed separately for the left and right hemispheres. In addition, there is an overarching column <code>Overall_subcortical_QC</code>. This can be set to <code>fail</code> when all individual regions fail (please still put <code>fail</code> for each column). If <code>Overall_subcortical_QC</code> is set to fail, the subject will be excluded from the subcortical analysis.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#3-familiarize-yourself-with-enigma-quality-control-standards","title":"3. Familiarize yourself with ENIGMA quality control standards","text":"<p>Before starting, review the ENIGMA quality control instructions, including common segmentation errors and regions that are more prone to segmentation failure. You can find the ENIGMA manuals, adapted for the PD group below: - ENIGMA-PD Cortical Quality Control Manual   - Version of the cortical quiz slides including the answers to the quiz - ENIGMA-PD Subcortical Quality Control Manual</p> <p>We recommend not focusing too heavily on the manuals. Though they do provide some useful examples, hands-on practice is key to learning quality control, and the quality of someone\u2019s visual assessment improves primarily through experience.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#4-check-out-the-fsqc-generated-html-page-with-screenshots","title":"4. Check out the fsqc-generated html page with screenshots","text":"<p>Open the <code>fsqc-results.html</code> in your browser. This page shows several different images for each subject of your dataset: - Screenshots: For internal quality control of the cortical areas and to inspect the subcortical areas - Skullstrip: To confirm whether skullstripping was successful. If skullstripping failed, regions that are not covered by the extracted brain mask (but should have been) and possibly those near the edges of the brain will fail quality control (for example, the cerebellum).  - Surfaces: For external quality control of the cortical areas - Hypothalamus: For quality control of the hypothalamus subsegmentations - Hippocampus: For quality control of the hippocampus and amygdala subsegmentations</p> <p>For a walkthrough of how these look in practice, check out the FSQC tour.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#5-cortical-quality-control","title":"5. Cortical Quality Control","text":""},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#warm-up-dynamically-check-a-few-subjects-across-all-regions","title":"Warm-up: dynamically check a few subjects across all regions","text":"<p>Start by quickly scrolling through around 5\u201310 subjects to get a sense of the typical variability in cortical segmentations. This dynamic review helps you become familiar with how correctly segmented regions usually appear and what kinds of errors to expect.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#for-the-full-dataset-go-per-region","title":"For the full dataset, go per region","text":"<p>Most raters prefer evaluating one cortical region at a time across all subjects. This helps with consistency and speeds up spotting systematic issues. As you go, flag any doubtful cases, either to revisit later or to share with the ENIGMA core team for second opinion.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#6-subcortical-quality-control","title":"6. Subcortical Quality Control","text":"<p>After the cortical regions, the subcortical quality control is a piece of cake. Subcortical regions are located close together and can usually be assessed in a single glance (in contrast to the region-by-region approach of the cortical segmentations). Segmentation errors are uncommon, and most regions should pass. Approve unless there are clear, severe distortions, which often affect multiple or all neighboring subcortical regions rather than just one.</p>"},{"location":"resources/how_to_guides/ENIGMA_visual_QC_instructions/#things-to-keep-in-mind","title":"Things to Keep in Mind","text":"<ul> <li>Be lenient: Only exclude segmentations with clear, severe errors that would lead to invalid regional estimates.  </li> <li>As you review more subjects, it becomes easier to recognize these major failures quickly.  </li> <li>When in doubt, keep the data, borderline cases are usually acceptable for analysis.</li> </ul>"},{"location":"resources/how_to_guides/Templateflow_info/","title":"Templateflow info","text":""},{"location":"resources/how_to_guides/Templateflow_info/#clarifications-about-templateflow","title":"Clarifications about Templateflow","text":"<p>Templateflow is a library of neuroimaging templates (e.g. <code>MNI152NLin2009cAsym</code>) used by several popular processing pipelines, including fMRIPrep (which we are using to run FreeSurfer 7) and MRIQC.</p> <p>By default the templates are stored in <code>~/.templateflow</code>, but in general it is a good idea to store them somewhere more central/visible, so that the same templates can be used by different people in a research group. Another reason to specify another path is that the home directory often has limited storage on some servers.   - In the Nipoppy global config file, <code>&lt;PATH_TO_TEMPLATEFLOW_DIRECTORY&gt;</code> should be replaced by the path to an empty directory, possibly in a similar location as (parallel to) the container store directory.</p> <p>The first time fMRIPrep is run, it will attempt to download templates to the Templateflow directory, which will require the computer to be connected to the internet. If you are running fMRIPRep on a cluster where compute nodes do not have access to the Internet, see here and feel free to reach out to us for help.</p>"},{"location":"resources/how_to_guides/freesurfer7/","title":"Welcome to the ENIGMA-infra FreeSurfer 7 guidelines!","text":""},{"location":"resources/how_to_guides/freesurfer7/#prerequisites","title":"Prerequisites","text":"<p>This guide assumes that you have:</p> <ul> <li>installed Nipoppy and organized your data in BIDS</li> <li>Apptainer available as container platform</li> </ul>"},{"location":"resources/how_to_guides/freesurfer7/#pull-container","title":"Pull container","text":"<p>We will apply the FreeSurfer functionalities that are included in the fMRIPrep pipeline. You can pull the fMRIPrep container in the following way:</p> <pre><code>apptainer build fmriprep_24.1.1.sif \\\n                    docker://nipreps/fmriprep:24.1.1\n</code></pre> <p>Make sure that you store the container in the containers folder that is referenced in your global config file.</p> <p>For more information on fMRIPrep, see the fMRIPrep documentation.</p>"},{"location":"resources/how_to_guides/freesurfer7/#set-up-configuration","title":"Set up configuration","text":"<p>Next, we will need to install the fMRIPrep pipeline within Nipoppy. You can do this by simply running:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 15427833\n</code></pre> <p>15427833 is the Zenodo ID for the Nipoppy configuration files for fmriprep 24.1.1. Read more about this step here.</p> <p>Once the pipeline is installed, open the global config file and check whether the correct fMRIPrep version is included under <code>PIPELINE_VARIABLES</code>. The following paths should be replaced here under the correct version of the fMRIPrep pipeline in the global config file: - <code>&lt;FREESURFER_LICENSE_FILE&gt;</code> (required to run FreeSurfer; you can get a FreeSurfer licence for free at the FreeSurfer website) - <code>&lt;TEMPLATEFLOW_HOME&gt;</code> (see here for more info on Templateflow)</p>"},{"location":"resources/how_to_guides/freesurfer7/#run-pipeline","title":"Run pipeline","text":"<p>Finally, simply run the following line of code:</p> <pre><code>nipoppy process --pipeline fmriprep --pipeline-version 24.1.1 --dataset &lt;dataset_root&gt;\n</code></pre> <p>This should initiate the FreeSurfer 7 segmentation of your T1-weighted images! You can also do a dry-run first by adding <code>--simulate</code> to your command. See all <code>nipoppy process</code> options here</p> <p>Note: the command above will run all the participants and sessions in a loop, which may be inefficient. If you're using an HPC, you may want to submit a batch job to process all participants/sessions. Nipoppy can help you do this by: 1. generating a list of \"remaining\" participants to be processed for your job-subission script: <code>nipoppy process --pipeline fmriprep --pipeline-version 24.1.1 --dataset &lt;dataset_root&gt; --write-list &lt;path_to_participant_list&gt;</code> 2. automatically submitting HPC jobs for you with additional configuration (more info here)</p>"},{"location":"resources/how_to_guides/freesurfer7/#track-pipeline-output","title":"Track pipeline output","text":"<p>The <code>nipoppy track-processing</code> command can help keep track of which participants/sessions have all the expected output files for a given processing pipeline. See here for more information. </p> <pre><code>nipoppy track-processing --pipeline fmriprep --dataset &lt;dataset_root&gt;\n</code></pre> <p>Running this command will update the <code>processing_status.tsv</code> under the <code>derivatives</code> folder.</p>"},{"location":"resources/how_to_guides/freesurfer7/#extract-pipeline-output","title":"Extract pipeline output","text":"<p>For automatic extraction of the cortical thickness, cortical surface area and subcortical volume into .tsv files, you can use another Nipoppy pipeline, called <code>fs_stats</code>. The Zenodo ID for this pipeline is 15427856, so you can install it with the following command:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 15427856\n</code></pre> <p>Remember to define the freesurfer license file path in your global config file under the newly installed pipeline. Then, you can simply run </p> <pre><code>nipoppy extract --pipeline fs_stats --dataset &lt;dataset_root&gt;\n</code></pre> <p>to get things going. You can find the extracted data under <code>&lt;dataset_root&gt;/derivatives/freesurfer/7.3.2/idp/</code>.</p> <p>Did you complete all FreeSurfer 7 processing and data extraction? Great job! You can now move on to the subsegmentation, or go straight to quality control.</p>"},{"location":"resources/how_to_guides/freesurfer_subseg/","title":"Welcome to the ENIGMA-infra FreeSurfer subsegmentations guidelines!","text":""},{"location":"resources/how_to_guides/freesurfer_subseg/#prerequisites","title":"Prerequisites","text":"<p>This guide assumes that you have:</p> <ul> <li>installed Nipoppy and organized your data in BIDS</li> <li>Apptainer available as container platform</li> <li>performed FreeSurfer 7 processing</li> </ul>"},{"location":"resources/how_to_guides/freesurfer_subseg/#about-the-pipeline","title":"About the pipeline","text":"<p>This pipeline uses existing FreeSurfer 7 functionalities to extract subnuclei volumes from subcortical regions like the thalamus, hippocampus, brainstem, hypothalamus, amygdala, and hippocampus. It requires completed FreeSurfer output (<code>recon-all</code>) and integrates the subsegmentation outputs directly into the existing <code>/mri</code> and <code>/stats</code> directories. Additionally, the pipeline will perform Sequence Adaptive Multimodal SEGmentation (SAMSEG) on T1w images in order to calculate a superior total intracranial volume (TIV).</p>"},{"location":"resources/how_to_guides/freesurfer_subseg/#pull-container","title":"Pull container","text":"<p>You need to download the container image that will run the subsegmentations. Use the following Apptainer command to pull the image from Docker Hub:</p> <pre><code>apptainer build freesurfer_subseg_1.0.sif docker://nichyconsortium/freesurfer_subseg:1.0\n</code></pre> <p>Make sure the resulting image file is stored in the container directory referenced in your global config file.</p>"},{"location":"resources/how_to_guides/freesurfer_subseg/#set-up-configuration","title":"Set up configuration","text":"<p>To get the Nipoppy specification files for the subsegmentation container, run:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 15877956\n</code></pre> <p>Read more about this step here.</p> <p>Note: If you have multiple T1w images per subject per session, the container will throw an error. In this case, you will need to open the invocation file under <code>&lt;dataset_root&gt;/pipelines/processing/freesurfer_subseg-1.0/</code> and specify the name of the desired T1w image for SAMSEG in the following way:</p> <pre><code>\"t1_image_path\": \"[[NIPOPPY_BIDS_PARTICIPANT_ID]]_[[NIPOPPY_BIDS_SESSION_ID]]_&lt;edit-me&gt;_T1w.nii.gz\"\n</code></pre>"},{"location":"resources/how_to_guides/freesurfer_subseg/#change-global-config-file","title":"Change global config file","text":"<p>Open the global config file and add the path to your freesurfer license file under the freesurfer_subseg pipeline, just like you did for the fMRIPrep pipeline:</p> <pre><code>\"PIPELINE_VARIABLES\": {\n  \"BIDSIFICATION\": {},\n  \"PROCESSING\": {\n    \"fmriprep\": {\n      \"24.1.1\": {\n        \"FREESURFER_LICENSE_FILE\": \"path/to/license/file/license.txt\",\n        \"TEMPLATEFLOW_HOME\": \"path/to/templateflow/\"\n      }\n    },\n    \"freesurfer_subseg\": {\n      \"1.0\": {\n        \"FREESURFER_LICENSE_FILE\": \"path/to/license/file/license.txt\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"resources/how_to_guides/freesurfer_subseg/#final-check","title":"Final check","text":"<p>Before trying to run the pipeline, confirm that the pipeline is recognized by running <code>nipoppy pipeline list</code>. This will print a list of the available pipelines.</p>"},{"location":"resources/how_to_guides/freesurfer_subseg/#run-pipeline","title":"Run pipeline","text":"<p>To run the subsegmentation pipeline, use the following command:</p> <pre><code>nipoppy process --pipeline freesurfer_subseg --pipeline-version 1.0 --dataset &lt;dataset_root&gt;\n</code></pre> <p>Note: In case you want to submit a batch job to process all participants/sessions, you can find more info here.</p>"},{"location":"resources/how_to_guides/freesurfer_subseg/#track-pipeline-output","title":"Track pipeline output","text":"<p>Use the <code>nipoppy track-processing</code> command to check which participants/sessions have complete output:</p> <pre><code>nipoppy track-processing --pipeline freesurfer_subseg --dataset &lt;dataset_root&gt;\n</code></pre> <p>This helps you confirm whether the pipeline ran successfully across your dataset (again, check <code>processing_status.tsv</code> under the <code>derivatives</code> folder).</p>"},{"location":"resources/how_to_guides/freesurfer_subseg/#extract-pipeline-output","title":"Extract pipeline output","text":"<p>For automatic extraction of the subsegmentation metrics and SAMSEG TIV into one .tsv file, you can use the <code>fs_subseg_stats</code> pipeline. The Zenodo ID for this pipeline is 17800572, so you can install it with the following command:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 17800572\n</code></pre> <p>When the pipeline is installed, you may need to change the permission of the downloaded python script. Go to <code>&lt;dataset_root&gt;/pipelines/extraction/fs_subseg_stats-0.2/</code> and run <code>chmod 777 fs_subseg_stats.py</code>. Then, you can simply run</p> <pre><code>nipoppy extract --pipeline fs_subseg_stats --dataset &lt;dataset_root&gt;\n</code></pre> <p>to get things going. You can find the extracted data under <code>&lt;dataset_root&gt;/derivatives/freesurfer_subseg/1.0/idp/fs_subseg_stats-0.2/</code>.</p> <p>Now, it's time to continue with quality control or get ready for data sharing!</p>"},{"location":"resources/how_to_guides/fsqc/","title":"Welcome to the ENIGMA-infra FreeSurfer Quality Control (fsqc) guidelines!","text":""},{"location":"resources/how_to_guides/fsqc/#prerequisites","title":"Prerequisites","text":"<p>This guide assumes that you have:</p> <ul> <li>installed Nipoppy and organized your data in BIDS</li> <li>Apptainer available as container platform</li> <li>performed FreeSurfer 7 processing</li> <li>performed FreeSurfer subsegmentation (not a hard requirement)</li> </ul>"},{"location":"resources/how_to_guides/fsqc/#about-the-fsqc-toolbox","title":"About the fsqc toolbox","text":"<p>Congratulations, you made it to the quality assessment! For this purpose, we will use the FreeSurfer Quality Control (fsqc) toolbox. The fsqc toolbox takes existing FreeSurfer (or FastSurfer) output and computes a set of quality control metrics. These will be reported in a summary table and/or .html page with screenshots to allow for visual inspection of the segmentations.</p>"},{"location":"resources/how_to_guides/fsqc/#pull-the-container","title":"Pull the container","text":"<p>You need to download the container image that will run the FreeSurfer Quality Control pipeline. Use the following command to pull the image from Docker Hub:</p> <pre><code>apptainer build fsqc_2.1.4.sif docker://deepmi/fsqcdocker:2.1.4\n</code></pre> <p>Make sure the resulting image file is stored in the container directory referenced in your global config file.</p>"},{"location":"resources/how_to_guides/fsqc/#set-up-configuration","title":"Set up configuration","text":"<p>To get the Nipoppy specification files for the fsqc container, run:</p> <pre><code>nipoppy pipeline install --dataset &lt;dataset_root&gt; 17100133\n</code></pre> <p>Read more about this step here.</p>"},{"location":"resources/how_to_guides/fsqc/#change-global-config-file","title":"Change global config file","text":"<p>Open the global config file and add the correct freesurfer version (7.3.2) under the fsqc pipeline.</p>"},{"location":"resources/how_to_guides/fsqc/#final-check","title":"Final check","text":"<p>Before trying to run the pipeline, confirm that the pipeline is recognized by running <code>nipoppy pipeline list</code>. This will print a list of the available pipelines.</p>"},{"location":"resources/how_to_guides/fsqc/#run-the-pipeline","title":"Run the pipeline","text":"<p>To run the fsqc pipeline, use the following command:</p> <pre><code>nipoppy process --pipeline fsqc --pipeline-version 2.1.4 --pipeline-step process --dataset &lt;dataset_root&gt;\n</code></pre>"},{"location":"resources/how_to_guides/fsqc/#expected-output","title":"Expected output","text":"<p>After running the command, you will find all results inside the derivatives folder. The output will include: - Several folders, most of them corresponding to the flags used in the command, such as: <code>screenshots</code>, <code>surfaces</code>, <code>skullstrip</code>, <code>hypothalamus</code>, <code>hippocampus</code>, and also, <code>status</code>, <code>metrics</code> - A CSV file (<code>fsqc-results.csv</code>) summarizing quantitative quality control metrics for all subjects. - A main HTML summary file (<code>fsqc-results.html</code>) that aggregates all subject screenshots for easy visual inspection.</p> <p>You can verify that images were created for all subjects by running:</p> <pre><code>nipoppy track-processing --pipeline fsqc --pipeline-step process-tracking --dataset &lt;dataset_root&gt;\n</code></pre> <p>and checking <code>processing_status.tsv</code> under the <code>derivatives</code> folder.</p> <p>When all required files are there, you are ready to move on to the visual inspection!</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/","title":"getting ENIGMA PD pipeline config files","text":""},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#getting-the-nipoppy-pipeline-specification-files-for-a-new-pipeline","title":"Getting the Nipoppy pipeline specification files for a new pipeline","text":"<p>To run pipeline containers within Nipoppy, you need to download the required pipeline configuration files from Zenodo. Together, these files allow Nipoppy to recognize, configure, run, and monitor the custom container image as part of its structured processing framework. You will need the following:</p> <ul> <li><code>descriptor.json</code></li> <li><code>invocation.json</code></li> <li><code>config.json</code></li> <li><code>tracker_config.json</code></li> </ul> <p>A quick way to download these four files is by running: <code>nipoppy pipeline install --dataset &lt;DATASET_ROOT&gt; &lt;ZENODO_ID&gt;</code></p> <p>Please read more instructions about adding a pipeline to a dataset on the nipoppy documentation page.</p> <p>Note: Every time a new pipeline is installed, you will need to change some paths in the global config file, depending on the pipeline.</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#examples","title":"Examples","text":""},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#fmriprep","title":"fmriprep","text":"<p>Latest pipeline version: <code>fmriprep-24.1.1</code></p> <p>Zenodo id: 15427833</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#freesurfer_subseg","title":"freesurfer_subseg","text":"<p>Latest pipeline version: <code>freesurfer_subseg-1.0</code></p> <p>Zenodo id: 15877956</p>"},{"location":"resources/how_to_guides/getting_ENIGMA-PD_pipeline_config_files/#fsqc","title":"fsqc","text":"<p>Latest pipeline version: <code>fsqc-2.1.1</code></p> <p>Zenodo id: 16810923</p>"},{"location":"resources/how_to_guides/pipeline_config_files_nipoppy/","title":"Getting the Nipoppy pipeline specification files for a new pipeline","text":"<p>To run pipeline containers within Nipoppy, you need to download the required pipeline configuration files from Zenodo. Together, these files allow Nipoppy to recognize, configure, run, and monitor the custom container image as part of its structured processing framework. You will need the following:</p> <ul> <li><code>descriptor.json</code></li> <li><code>invocation.json</code></li> <li><code>config.json</code></li> <li><code>tracker_config.json</code></li> </ul> <p>A quick way to download these four files is by running: <code>nipoppy pipeline install --dataset &lt;DATASET_ROOT&gt; &lt;ZENODO_ID&gt;</code></p> <p>Please read more instructions about adding a pipeline to a dataset on the nipoppy documentation page.</p> <p>Note: Every time a new pipeline is installed, you will need to change some paths in the global config file, depending on the pipeline.</p>"},{"location":"resources/how_to_guides/pipeline_config_files_nipoppy/#examples","title":"Examples","text":""},{"location":"resources/how_to_guides/pipeline_config_files_nipoppy/#fmriprep","title":"fmriprep","text":"<p>Latest pipeline version: <code>fmriprep-24.1.1</code></p> <p>Zenodo id: 15427833</p>"},{"location":"resources/how_to_guides/pipeline_config_files_nipoppy/#freesurfer_subseg","title":"freesurfer_subseg","text":"<p>Latest pipeline version: <code>freesurfer_subseg-1.0</code></p> <p>Zenodo id: 15877956</p>"},{"location":"resources/how_to_guides/pipeline_config_files_nipoppy/#fsqc","title":"fsqc","text":"<p>Latest pipeline version: <code>fsqc-2.1.1</code></p> <p>Zenodo id: 16810923</p>"},{"location":"resources/how_to_guides/qa/","title":"Welcome to the ENIGMA-infra guidelines for cortical and subcortical visual inspection!","text":""},{"location":"resources/how_to_guides/qa/#quality-assessment-performing-visual-inspection","title":"Quality Assessment: Performing visual inspection","text":"<p>Quality checking is essential to make sure the output that you have produced is accurate and reliable. Even small errors or artifacts in images can lead to big mistakes in analysis and interpretation, so careful checks help us to verify whether we can safely include a certain region of interest or participant in our analysis. For the FreeSurfer output, we will follow standardized ENIGMA instructions on how to decide on the quality of the cortical and subcortical segmentations. At this stage, visual quality assessment of the subsegmentations (e.g., thalamic or hippocampal nuclei) is not required, as there are no established protocols yet and the process would be highly time-consuming; statistical checks (e.g., outlier detection) can be used instead. This may be followed up at a later stage, once there is a project that specifically focuses on these outcomes and the necessary anatomical expertise is available to develop a dedicated quality control manual.</p>"},{"location":"resources/how_to_guides/qa/#important-notes-for-viewing-and-copying-files","title":"Important notes for viewing and copying files","text":""},{"location":"resources/how_to_guides/qa/#locally","title":"Locally","text":"<ul> <li>We strongly recommend downloading the entire output folder locally before opening the HTML file. Opening the HTML on a server or network drive is often slow and may cause images not to load properly.</li> <li>When copying files, make sure to include all generated folders (such as <code>screenshots</code>, <code>surfaces</code>, etc.) along with the <code>fsqc-results.html</code> file. These folders contain the images referenced in the HTML and are essential for proper display.</li> </ul>"},{"location":"resources/how_to_guides/qa/#on-the-server","title":"On the server","text":"<ul> <li>If you have not experienced such issues before and prefer to work directly on your server, you can instead open the HTML file in your available browser (for example: <code>firefox fsqc-results.html</code>).</li> </ul>"},{"location":"resources/how_to_guides/qa/#final-check","title":"Final check","text":"<ul> <li>When opening the <code>fsqc-results.html</code> file:  </li> <li>Scroll through the subjects to confirm all images load and no data is missing.  </li> <li>Click on any image to zoom in, or right-click and choose \u201cOpen in new tab\u201d and inspect details more closely.</li> </ul> <p>You can find the updated ENIGMA-PD QC instructions for visual inspection here.</p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/","title":"Welcome to the ENIGMA-infra guidelines for setting up Nipoppy!","text":""},{"location":"resources/how_to_guides/setting_up_nipoppy/#what-is-nipoppy","title":"What is Nipoppy?","text":"<p>Nipoppy is a lightweight framework for standardized data organization and processing of neuroimaging-clinical datasets. Its goal is to help users adopt the FAIR principles and improve the reproducibility of studies. </p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/#why","title":"Why?","text":"<p>The figure shows the expected outcomes and corresponding processing steps - most of which can be performed using the Nipoppy framework and helper Python package. We strongly recommend adoption of Nipoppy tools to simplify coordination and ensure reproducibility of this end-to-end process across all sites.  </p> <p>The ongoing collaboration between the ENIGMA working groups and Nipoppy team has streamlined data curation, processing, and analysis workflows, which significantly simplifies tracking of data availability, addition of new pipelines and upgrading of existing pipelines. The ENIGMA and Nipoppy teams are available to support and guide users through the process of implementing the framework, ensuring a smooth transition. To join the Nipoppy support community, we recommend joining the Discord channel. Here you can ask questions and find answers while working with Nipoppy. </p> <p>In the context of ENIGMA working groups, we will primairly use Nipoppy to help you with BIDSification and to facilitate easy processing with pipelines (such as FreeSurfer processing).</p> <p>For more information, see the Nipoppy documentation.</p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/#getting-started","title":"Getting started","text":"<p>To install Nipoppy, we refer to the Installation page. </p> <p>Once Nipoppy is successfully installed, you will need to create a Nipoppy dataset and populate it with your data. There are a few different starting points depending on the current state of your dataset. If you have your data already in BIDS format, click here. If you have DICOM of NIFTI files that are not yet in BIDS, continue below. If you're not sure what BIDS is or if you're wondering why you should convert your data into BIDS at all, you can find more info here.</p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/#starting-from-source-data-either-dicoms-or-niftis-that-are-not-yet-in-bids","title":"Starting from source data (either DICOMs or NIfTIs that are not yet in BIDS)","text":"<p>This is the scenario assumed by the Nipoppy Quickstart page. Follow this guide to: 1. Create an empty Nipoppy dataset (i.e. directory tree) 2. Write a manifest file representing your data 3. Modify the global config file with paths to e.g., path to your container directory</p> <p>Note: if your dataset is cross-sectional (i.e. only has one session), you still need to create a <code>session_id</code> for the manifest. In this case the value would be the same for all participants.</p> <p>When you reach the end of the Quickstart, it is time to copy and reorganize your raw imaging data to prepare them for BIDS conversion. Once this is done, you can find how to perform the BIDSification within the Nipoppy framework here. We recommend applying a containerized BIDS-conversion pipeline that can be run within Nipoppy. Here you can find how to download containers and here you can find how to run them within Nipoppy.</p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/#starting-with-bidsified-data","title":"Starting with BIDSified data","text":"<p>If your dataset is already in BIDS, then the manifest-generation step can be skipped by initializing the Nipoppy dataset with this command, specifying the path to your new dataset and the path to your existing BIDS data:</p> <pre><code>nipoppy init --dataset &lt;dataset_root&gt; --bids-source &lt;path_to_existing_bids_data&gt;\n</code></pre> <p>This command will create a Nipoppy dataset (i.e. directory tree) from preexisting BIDS dataset and automatically generate a manifest file for you! </p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/#bids-datasets-without-sessions","title":"BIDS datasets without sessions","text":"<p>If the existing BIDS data does not have session-level folders, Nipoppy will create \"dummy sessions\" (called <code>unnamed</code>) in the manifest. This is because the Nipoppy manifest still requires a non-empty <code>session_id</code> value when imaging data is available for a participant.</p> <p>If it is feasible to redo the BIDSification to include session folders, we recommend doing so since this is considered good practice. Otherwise, Nipoppy can still be run, but you will need to make some manual changes. For more information, see here</p>"},{"location":"resources/how_to_guides/setting_up_nipoppy/#starting-from-data-already-processed-with-freesurfer7","title":"Starting from data already processed with FreeSurfer7","text":"<p>We still encourage you to use Nipoppy to organize your source and/or BIDS data with your processed FS7 output to make use of automated trackers and downstream subsegmentation processing. However, you may need to some help depending on your version of FreeSurfer and naming convention of <code>participant_id</code>. Reach out to us on our Discord channel and we would be happy to help! </p>"},{"location":"resources/open_science_tools/BIDS_info/","title":"Why do BIDSification?","text":"<p>Before starting the analysis, organizing your data is essential \u2014 it will benefit this analysis and streamline any follow-up ENIGMA-PD work. We know it can be challenging, but we\u2019re here to support you. The Brain Imaging Data Structure (BIDS) format is a standardized format for organizing and labeling neuroimaging data to ensure consistency and make data easily shareable and analyzable across studies. Although we\u2019re focusing on T1-weighted images for this analysis, organizing available diffusion-weighted or functional MRI data in BIDS will make future analyses easier.</p> <p>Here are the core principles for organizing your neuroimaging data in BIDS format: - Use consistent file and folder names - Separate modalities - Include metadata files - Validate the structure</p> <p>Resources from the BIDS community offer guidance on organizing your data, and BIDS converters can help automate this process, saving time and reducing manual errors. We recommend using Dcm2Bids (for DICOM's) and BIDScoin (for NIfTI's).</p> <ul> <li>BIDS documentation</li> <li>Recommended converter: BIDScoin</li> <li>BIDS tutorials</li> </ul>"},{"location":"resources/open_science_tools/container_platforms/","title":"Installing and using containers with Nipoppy","text":""},{"location":"resources/open_science_tools/container_platforms/#overview-of-containers","title":"Overview of containers","text":"<p>We will be using containerized pipelines for data processing. This means that they are self-contained software environments that package all the tools, dependencies, and code needed to run each step of a data analysis pipeline reproducibly and consistently across systems. To download and run containers, you need a container platform, either Apptainer/Singularity or Docker. We strongly suggest Apptainer/Singularity, which is fully supported by Nipoppy. Docker can be used if you have admin rights to the computer/server you are using, or you work on something other than a Linux system (like a Mac). Using Nipoppy with Docker is possible though will likely require additional help -- reach out to us on our Discord channel and we would be happy to chat!</p> <p> Image generated using Microsoft Copilot.</p>"},{"location":"resources/open_science_tools/container_platforms/#checking-for-an-existing-installation","title":"Checking for an existing installation","text":"<p>You may already have apptainer/singularity installed on your machine. You can try this by simply running <code>apptainer</code> or <code>singularity</code> in your command line and see if it throws an error. Sometimes you will need to load it to your environment, for example by running <code>module load apptainer</code>. If you don't have a container platform installed, you can find how to do this below.</p>"},{"location":"resources/open_science_tools/container_platforms/#installing-a-container-platform","title":"Installing a container platform","text":"<ul> <li>Install Apptainer</li> <li>Install Docker</li> </ul> <p>Note: In some environments (e.g. shared servers), you may not be allowed to install software yourself. In that case, please contact your system administrators and request that they install Apptainer for you. </p>"},{"location":"resources/open_science_tools/container_platforms/#building-and-pulling-containers","title":"Building and pulling containers","text":"<p>Most containers used in scientific pipelines are built by developers and then hosted online (for example, on Docker Hub or other registries). What you actually download is a container image, which is a file that packages all the necessary software and dependencies.  </p> <p>For Apptainer, this image is stored as a single <code>.sif</code> file (Singularity Image Format). You do not need to build everything from scratch, instead, you can pull the image from the cloud and convert it into a <code>.sif</code> container with a single command.  </p> <p>This process is: - Reproducible \u2013 everyone pulls the exact same software environment. - Safe \u2013 the build command only creates the <code>.sif</code> file and does not change your system. </p>"},{"location":"resources/open_science_tools/container_platforms/#example-commands","title":"Example commands","text":"<p>For Apptainer, run:</p> <pre><code>apptainer build &lt;pipeline&gt;_&lt;version&gt;.sif \\\n                    docker://&lt;repository&gt;/&lt;pipeline&gt;:&lt;version&gt;\n</code></pre> <p>For docker, run:</p> <pre><code>docker pull &lt;repository&gt;/&lt;pipeline&gt;:&lt;version&gt;\n</code></pre>"},{"location":"resources/open_science_tools/container_platforms/#storing-container-images","title":"Storing container images","text":"<p>Nipoppy encourages the use of a common directory for storing container images, which can be shared across datasets/individuals. This directory can be anywhere on a system. </p> <p>Note: In the global config file, <code>&lt;NIPOPPY_DPATH_CONTAINERS&gt;</code> should be replaced by the actual path to that directory. We encourage you to create a symlink (= a shortcut pointing to another file or directory, allowing access from a different location without copying the original) from the <code>&lt;DATASET_ROOT&gt;/containers directory</code> inside the Nipoppy dataset to the shared container store location. This makes it easy for anyone inspecting the dataset to find the containers. If you create this symlink, you don\u2019t need to set <code>&lt;NIPOPPY_DPATH_CONTAINERS&gt;</code> manually, because Nipoppy will automatically use <code>&lt;DATASET_ROOT&gt;/containers</code> by default.</p>"},{"location":"resources/open_science_tools/open_science_toolstack/","title":"Open Science Toolstack (OST)","text":""},{"location":"resources/open_science_tools/open_science_toolstack/#the-ost-consists-of-tools-to-facilitate-fairification-of-neuroimaging-data-workflows-in-a-decentralized-multi-site-setup","title":"The OST consists of tools to facilitate FAIRification of neuroimaging data workflows in a decentralized multi-site setup.","text":"<ul> <li> Nipoppy   A lightweight framework for standardized organization and processing </li> <li> Neurobagel   An ecosystem for distributed dataset harmonization and search</li> </ul>"},{"location":"resources/open_science_tools/open_science_toolstack/#underlying-community-standards-and-technology","title":"Underlying community standards and technology","text":"<ul> <li>Brain Imaging Data Structure </li> <li>Containers (Apptainer / Docker) </li> </ul>"},{"location":"reviews/Bangalore/","title":"Dr. Shweta Prasad, NIMHANS, India (Enigma-Tremor)","text":"<p>NIMHANS is a renowned research institute-hospital in Bangalore, India with state-of-the-art scanners and highly-skilled clinicians. With a high-volume of patients, we collect large amounts of scans (&gt;20/month) to be analyzed within a single study. But, typically running advanced analytic pipelines becomes a major challenge for the research projects due to time constraints and technical expertise needed for systematic data management. This is where Nipoppy tools and the ORIGAMI team behind has been a great help! Nipoppy tools are extremely easy to use, they come with extensive documentation and the ORIGAMI team is quick to provide hands-on support. Nipoppy has helped automate our workflows and process large datasets efficiently with many different pipelines. This is especially useful as we are starting to join consortia (ENIGMA-tremor) where consistent and reproducible image processing across sites is critical.</p>"},{"location":"reviews/Campinas/","title":"Raphael Fernandes Casseb, PhD University of Campinas, Brazil (Enigma-PD)","text":"<p>We have participated in other multicenter projects and we were aware that projects at the very beginning are not 100% fault-proof. We indeed had a few difficulties in setting up the computing cluster, because our system runs an older Linux version and we did not initially know all the pipeline parameters we would have to set. We reached out to the researchers and developers\u2014especially Eva, Michelle, and Nikhil\u2014who were extremely accessible and supportive throughout the process. We initially had a meeting with Eva who was quite attentive and helpful in pointing directions on how to set up some of the BIDs conversion scripts. Later, we had trouble installing apptainer, and Michelle and Nikhil gave us some hints on what we could do. Finally, we had a few issues with nippopy scripts. Michelle and Nikhil kindly helped us via online meetings and followed up on discord to guarantee everything was fine. In terms of workload, I initially expected the setup to take a little time. In reality, it took more time than planned, but their team provided all the assistance we needed. The outcome has been very positive and we were able to run all the analyses we wanted.  Regarding workshops and tutorials, I think they could keep doing exactly as they are doing: brief meetings with initial orientation and let users try it for themselves. Then, they can work with users individually to sort out specific problems. From my perspective, there is no point in hosting long sessions, considering that each user may be running a different system.</p>"},{"location":"reviews/Groningen/","title":"Anna Dortmond, Groningen, Netherlands","text":"<p>As a researcher without prior experience in MRI scan preprocessing or Python-based programming, I found Nipoppy to be an accessible and practical tool. While there were a few obstacles along the way\u2014such as getting the setup just right, as is often the case with these types of projects\u2014the team was always approachable and responsive to questions, and the online instructions were clear. The workshops, combined with practical application and guidance of the team, provided a solid understanding of the pipeline\u2019s structure. This made the process progressively more straightforward. We are now applying the pipeline in another project involving fMRI data, as it offers a structured and reproducible preprocessing workflow that can be readily implemented.</p>"},{"location":"reviews/Nijmegen/","title":"Martin E. Johansson, Nijmegen, Netherlands (ENIGMA-PD)","text":"<p>As an experienced MRI data wrangler, I was immediately intrigued by Nipoppy\u2019s and Neurobagel\u2019s potential to simplify data organization, harmonization, and interaction. At first, I feared that Nipoppy would be incompatible with my pre-existing, painstakingly BIDSified MRI data, forcing me to redo this procedure. However, after initializing a new data set with Nipoppy, I found that I could simply fill this new directory with symbolic links to my BIDSified MRI data. This has allowed me to take full advantage of the other features that Nipoppy offers. In particular, I really appreciate the ability to customize the generation of derivatives using the global configuration file. Next, I transitioned to Neurobagel. I found this latter tool to be very powerful when trying to find out how many scans I have at my disposal, particularly when looking at subsets of the data stratified by diagnosis and other demographic/clinical variables, a task I previously accomplished using exceedingly messy BaSH-coding with lots of IF-statements. While Neurobagel has been very useful, I found it somewhat difficult to set up and maintain the node required for using the query tool. However, after some quick hands-on assistance from members of the Origami team, I am now able to handle this step on my own as well.</p>"},{"location":"reviews/Singapore/","title":"Thomas Welton, PhD, Principal Investigator, National Neuroscience Institute, Singapore","text":"<p>Our team implemented Nipoppy in mid-2025 with the intention of contributing our data to the ENIGMA-PD Consortium. We attended an online workshop and followed the ENIGMA-PD Nipoppy implementation guide. We are technically proficient and were able to complete most of the work without any problem. After all, the Nipoppy documentation is quite clear and easy to follow. We did face a minor implementation challenge related to incompatible versions of software packages \u2013 this was due to our lab using an older Linux system. This was quickly fixed with help from the Nipoppy team. Nikhil Bhagwat joined us on a zoom call and later happened to be in the region, so attended our institute in Singapore to troubleshoot. Most conventional Linux set-ups should have no such issues. We have found the ENIGMA-PD and Nipoppy teams to be responsive to our queries by email, too. Overall, we did not spend a significant amount of time working on the Nipoppy implementation. Use of Nipoppy has the potential to accelerate our consortium\u2019s progress, so I fully support this initiative.</p>"},{"location":"reviews/testimonials/","title":"Testimonials","text":""},{"location":"reviews/testimonials/#what-are-the-early-adopters-saying","title":"What are the early adopters saying..","text":"<ul> <li> <p>Martin E. Johansson (Netherlands):  \"... I found this latter tool to be very powerful when trying to find out how many scans I have at my disposal, particularly when looking at subsets of the data stratified by diagnosis and other demographic/clinical variables, a task I previously accomplished using exceedingly messy BaSH-coding with lots of IF-statements ...\"</p> </li> <li> <p>Anna Dortmond (Netherlands):  \"... The workshops, combined with practical application and guidance of the team, provided a solid understanding of the pipeline\u2019s structure. This made the process progressively more straightforward ...\"</p> </li> <li> <p>Thomas Welton (Singapore):  \"... Our team implemented Nipoppy in mid-2025 with the intention of contributing our data to the ENIGMA-PD Consortium. We attended an online workshop and followed the ENIGMA-PD Nipoppy implementation guide ... Use of Nipoppy has the potential to accelerate our consortium\u2019s progress, so I fully support this initiative ...\"</p> </li> <li> <p>Raphael Fernandes Casseb, PhD (Brazil):  \"... We reached out to the researchers and developers\u2014especially Eva, Michelle, and Nikhil\u2014who were extremely accessible and supportive throughout the process. We initially had a meeting with Eva who was quite attentive and helpful in pointing directions on how to set up some of the BIDs conversion scripts ...\"</p> </li> <li> <p>Dr. Shweta Prasad (India):  \"... typically running advanced analytic pipelines becomes a major challenge for the research projects due to time constraints and technical expertise needed for systematic data management. This is where Nipoppy tools and the ORIGAMI team behind has been a great help! ...\"</p> </li> </ul>"},{"location":"team/people/","title":"Infra-core","text":"<p>Meet the people behind the project</p>"},{"location":"team/people/#principal-investigators","title":"Principal investigators","text":"<ul> <li> Ysbrand Van Der Werf   Amsterdam UMC, The Netherlands</li> <li> Jean-Baptiste Poline   McGill University, Montreal, Canada  </li> </ul>"},{"location":"team/people/#project-leads","title":"Project leads","text":"<ul> <li> Eva van Heese   Amsterdam UMC, The Netherlands  </li> <li> Nikhil Bhagwat   McGill University, Montreal, Canada  </li> <li> Emile d'Angremont   Amsterdam UMC, The Netherlands  </li> <li> Sebastian Urchs   McGill University, Montreal, Canada  </li> </ul>"},{"location":"team/people/#dev-leads","title":"Dev leads","text":"<ul> <li> Michelle Wang   McGill University, Montreal, Canada  </li> <li> Alyssa Dai    McGill University, Montreal, Canada  </li> <li> Mathieu Dugr\u00e9   Concordia University, Montreal, Canada  </li> <li> Arman Jahanpour   McGill University, Montreal, Canada  </li> </ul>"},{"location":"wg/wgs/","title":"ENIGMA Working Groups","text":"<ul> <li> <p> Parkinson's Disease</p> <p> Enigma-PD website </p> <p> enigma-pd@amsterdamumc.nl</p> </li> <li> <p> Tremor</p> <p> Enigma-Tremor website </p> <p> m.laansma@amsterdamumc.nl</p> </li> </ul>"},{"location":"blog/archive/2025/","title":"2025","text":""}]}